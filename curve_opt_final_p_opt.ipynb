{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec42dd55",
   "metadata": {},
   "source": [
    "# Cubic Bezier Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7450e12",
   "metadata": {},
   "source": [
    "Optimizes a cubic bezier curved-line path from a point on the viable brain surface region to a point on the subthalamic nucleus (STN) for DBS electrode planning.\n",
    "\n",
    "Treats the following as obstacles:\n",
    "- Sulci\n",
    "- Ventricles\n",
    "- Corpus Callosum (prevent brain crossing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ca02f",
   "metadata": {},
   "source": [
    "**Objective Functions**\n",
    "- Distance to obstacles\n",
    "- Minimum path distance  *(not optimized yet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258b1ef",
   "metadata": {},
   "source": [
    "Includes P1 and P2 optimization using differential evolution function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253184e",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0b5ab",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a94cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import vedo\n",
    "from vedo import Volume, show, Line, merge, Plotter, Points\n",
    "\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affb47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set vedo backend to pop out plots in separate windows\n",
    "vedo.settings.default_backend = '2d' # or 'vt' or '2d' or 'k3d' or 'ipyvtklink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984fbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Vedo sphere plot test\n",
    "# sphere = vedo.Sphere(pos=[0, 0, 0], c=\"red\", r=1.0)\n",
    "# plotter = vedo.Plotter()\n",
    "# plotter += sphere\n",
    "# plotter.show(axes=1, viewup='z', zoom=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427aa6a",
   "metadata": {},
   "source": [
    "### Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf206b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: ./FINAL_BRAIN_ATLAS/final_nii_files\n"
     ]
    }
   ],
   "source": [
    "# Define new base directory and sub-folder structure\n",
    "base_dir = \"./FINAL_BRAIN_ATLAS/final_nii_files\"\n",
    "\n",
    "# Entry zones (viable surface regions for path start)\n",
    "entry_zone_dir = os.path.join(base_dir, \"entry_zone\")\n",
    "left_entry_zone_dir = os.path.join(entry_zone_dir, \"LEFT_ENTRY_ZONE\")\n",
    "right_entry_zone_dir = os.path.join(entry_zone_dir, \"RIGHT_ENTRY_ZONE\")\n",
    "\n",
    "# Subthalamic nucleus (targets)\n",
    "stn_root_dir = os.path.join(base_dir, \"subthalamic_nucleus\")\n",
    "left_stn_dir = os.path.join(stn_root_dir, \"LEFT_STN\")\n",
    "right_stn_dir = os.path.join(stn_root_dir, \"RIGHT_STN\")\n",
    "\n",
    "# Full brain (for context / outline only)\n",
    "full_brain_dir = os.path.join(base_dir, \"full_brain\")\n",
    "\n",
    "# Skin surface (outer head/skin/skull)\n",
    "skin_dir = os.path.join(base_dir, \"skin\")\n",
    "\n",
    "# Obstacles (same role as before)\n",
    "obstacles_dir = os.path.join(base_dir, \"obstacles\")\n",
    "\n",
    "print(\"Base directory:\", base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da8d2c",
   "metadata": {},
   "source": [
    "### Load Brain Structures\n",
    "\n",
    "Recursively load all `.nii` / `.nii.gz` files under each designated root:\n",
    "- Entry Zones (LEFT/RIGHT) viable start regions (light brown, low alpha)\n",
    "- STN Targets (LEFT/RIGHT) (distinct greens)\n",
    "- Obstacles (red)\n",
    "- Full Brain outline (very light grey, minimal alpha)\n",
    "\n",
    "All subfolder contents are merged later per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16468e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Entry Zones (LEFT)...\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1003_posterior_part_of_left_middle_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1012_left_lateral_orbital_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1014_left_straight_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1017_left_paracentral_lobule.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1018_opercular_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1019_orbital_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1020_triangular_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1024_left_precentral_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1027_anterior_part_of_left_middle_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1028_left_superior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1032_left_frontal_pole.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1008_left_inferior_parietal_lobule.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1022_left_postcentral_gyrus.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1025_left_precuneus.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1029_left_superior_parietal_lobule.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1031_left_supramarginal_gyrus.nii\n",
      "Loading Entry Zones (RIGHT)...\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2003_posterior_part_of_right_middle_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2012_right_lateral_orbital_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2014_right_straight_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2017_right_paracentral_lobule.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2018_opercular_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2019_orbital_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2020_triangular_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2024_right_precentral_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2027_anterior_part_of_right_middle_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2028_right_superior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2032_right_frontal_pole.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2008_right_inferior_parietal_lobule.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2022_right_postcentral_gyrus.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2025_right_precuneus.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2029_right_superior_parietal_lobule.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2031_right_supramarginal_gyrus.nii\n",
      "\n",
      "Loading STN (LEFT)...\n",
      "  Loading structure: Model_391_left_subthalamic_nucleus.nii\n",
      "Loading STN (RIGHT)...\n",
      "  Loading structure: Model_390_right_subthalamic_nucleus.nii\n",
      "\n",
      "Loading Obstacles...\n",
      "  Loading structure: SULCI\\Model_5001_left_calcarine_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5002_right_calcarine_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5003_left_central_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5004_right_central_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5005_left_cingulate_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5006_right_cingulate_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5007_left_collateral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5008_right_collateral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5009_left_inferior_frontal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5010_right_inferior_frontal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5011_left_intraparietal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5012_right_intraparietal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5013_left_parieto-occipital_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5014_right_parieto-occipital_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5015_left_postcentral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5016_right_postcentral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5017_left_precentral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5018_right_precentral_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5019_left_superior_frontal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5020_right_superior_frontal_sulcus.nii\n",
      "  Loading structure: SULCI\\Model_5022_right_superior_temporal_sulcus.nii\n",
      "  Loading structure: VENTRICLE\\Model_15_fourth_ventricle.nii\n",
      "  Loading structure: VENTRICLE\\Model_19_aqueduct.nii\n",
      "  Loading structure: VENTRICLE\\Model_24_third_ventricle.nii\n",
      "  Loading structure: VENTRICLE\\Model_43_right_lateral_ventricle.nii\n",
      "  Loading structure: VENTRICLE\\Model_44_temporal_horn_of_right_lateral_ventricle.nii\n",
      "  Loading structure: VENTRICLE\\Model_4_left_lateral_ventricle.nii\n",
      "  Loading structure: VENTRICLE\\Model_5_temporal_horn_of_left_lateral_ventricle.nii\n",
      "\n",
      "Loading Full Brain Outline...\n",
      "  Loading structure: CEREBELLUM\\Model_46_white_matter_of_right_hemisphere_of_cerebellum.nii\n",
      "  Loading structure: CEREBELLUM\\Model_7_white_matter_of_left_hemisphere_of_cerebellum.nii\n",
      "  Loading structure: CORPUS_CALLOSUM\\Model_3004_corpus_callosum.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1003_posterior_part_of_left_middle_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1012_left_lateral_orbital_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1014_left_straight_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1017_left_paracentral_lobule.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1018_opercular_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1019_orbital_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1020_triangular_part_of_left_inferior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1024_left_precentral_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1027_anterior_part_of_left_middle_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1028_left_superior_frontal_gyrus.nii\n",
      "  Loading structure: LEFT_FRONTAL_LOBE\\Model_1032_left_frontal_pole.nii\n",
      "  Loading structure: LEFT_INSULA\\Model_1000_left_insula.nii\n",
      "  Loading structure: LEFT_INSULA\\Model_1035_left_limen_insulae.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_1002_caudal_part_of_left_anterior_cingulate_gyrus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_1010_isthmus_of_left_cingulate_gyrus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_1016_left_parahippocampal_gyrus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_1023_left_posterior_cingulate_gyrus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_1026_rostral_part_of_left_anterior_cingulate_gyrus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_17_left_hippocampus.nii\n",
      "  Loading structure: LEFT_LIMBIC_LOBE\\Model_18_left_amygdala.nii\n",
      "  Loading structure: LEFT_OCCIPITAL_LOBE\\Model_1005_left_cuneus.nii\n",
      "  Loading structure: LEFT_OCCIPITAL_LOBE\\Model_1011_left_lateral_occipital_gyrus.nii\n",
      "  Loading structure: LEFT_OCCIPITAL_LOBE\\Model_1013_left_lingual_gyrus.nii\n",
      "  Loading structure: LEFT_OCCIPITAL_LOBE\\Model_1021_left_visual_cortex.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1008_left_inferior_parietal_lobule.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1022_left_postcentral_gyrus.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1025_left_precuneus.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1029_left_superior_parietal_lobule.nii\n",
      "  Loading structure: LEFT_PARIETAL_LOBE\\Model_1031_left_supramarginal_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1001_left_superior_temporal_gyrus_(banks_of_left_superior_temporal_sulcus).nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1006_left_ambiens_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1007_left_fusiform_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1009_left_inferior_temporal_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1015_left_middle_temporal_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1030_left_superior_temporal_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1033_left_temporal_pole.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_1034_left_transverse_temporal_gyrus.nii\n",
      "  Loading structure: LEFT_TEMPORAL_LOBE\\Model_3001_left_claustrum.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2003_posterior_part_of_right_middle_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2012_right_lateral_orbital_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2014_right_straight_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2017_right_paracentral_lobule.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2018_opercular_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2019_orbital_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2020_triangular_part_of_right_inferior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2024_right_precentral_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2027_anterior_part_of_right_middle_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2028_right_superior_frontal_gyrus.nii\n",
      "  Loading structure: RIGHT_FRONTAL_LOBE\\Model_2032_right_frontal_pole.nii\n",
      "  Loading structure: RIGHT_INSULA\\Model_2000_right_insula.nii\n",
      "  Loading structure: RIGHT_INSULA\\Model_2035_right_limen_insulae.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_2002_caudal_part_of_right_anterior_cingulate_gyrus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_2010_isthmus_of_right_cingulate_gyrus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_2016_right_parahippocampal_gyrus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_2023_right_posterior_cingulate_gyrus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_2026_rostral_part_of_right_anterior_cingulate_gyrus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_53_right_hippocampus.nii\n",
      "  Loading structure: RIGHT_LIMBIC_LOBE\\Model_54_right_amygdala.nii\n",
      "  Loading structure: RIGHT_OCCIPITAL_LOBE\\Model_2005_right_cuneus.nii\n",
      "  Loading structure: RIGHT_OCCIPITAL_LOBE\\Model_2011_right_lateral_occipital_gyrus.nii\n",
      "  Loading structure: RIGHT_OCCIPITAL_LOBE\\Model_2013_right_lingual_gyrus.nii\n",
      "  Loading structure: RIGHT_OCCIPITAL_LOBE\\Model_2021_right_visual_cortex.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2008_right_inferior_parietal_lobule.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2022_right_postcentral_gyrus.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2025_right_precuneus.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2029_right_superior_parietal_lobule.nii\n",
      "  Loading structure: RIGHT_PARIETAL_LOBE\\Model_2031_right_supramarginal_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2001_right_superior_temporal_gyrus_(banks_of_right_superior_temporal_sulcus).nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2006_right_ambiens_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2007_right_fusiform_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2009_right_inferior_temporal_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2015_right_middle_temporal_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2030_right_superior_temporal_gyrus.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2033_right_temporal_pole.nii\n",
      "  Loading structure: RIGHT_TEMPORAL_LOBE\\Model_2034_right_transverse_temporal_gyrus.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_11_left_caudate_nucleus.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_12_left_putamen.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_13_left_globus_pallidus_pars_externa.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_25_left_globus_pallidus_pars_interna.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_26_left_nucleus_accumbens.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_2_white_matter_of_left_cerebral_hemisphere.nii\n",
      "  Loading structure: SUBCORTEX_OF_LEFT_CEREBRAL_HEMISPHERE\\Model_3007_left_fornix_of_forebrain.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_3005_right_fornix_of_forebrain.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_41_white_matter_of_right_cerebral_hemisphere.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_50_right_caudate_nucleus.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_51_right_putamen.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_52_right_globus_pallidus_pars_externa.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_58_right_nucleus_accumbens.nii\n",
      "  Loading structure: SUBCORTEX_OF_RIGHT_CEREBRAL_HEMISPHERE\\Model_83_right_globus_pallidus_pars_interna.nii\n",
      "\n",
      "Loading Skin Surface...\n",
      "  Loading structure: Model_3_skin.nii\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for different structure types\n",
    "left_entry_zone_structures = []\n",
    "right_entry_zone_structures = []\n",
    "left_stn_structures = []\n",
    "right_stn_structures = []\n",
    "allowed_left_entry_zone_structures = []\n",
    "allowed_right_entry_zone_structures = []\n",
    "obstacle_structures = []\n",
    "full_brain_structures = []\n",
    "skin_structures = []\n",
    "\n",
    "# Loader utility: walk all subfolders and load every .nii / .nii.gz\n",
    "def load_folder_surfaces(root_folder, color, alpha=1.0):\n",
    "    loaded = []\n",
    "    if not os.path.isdir(root_folder):\n",
    "        print(f\"[WARN] Folder not found: {root_folder}\")\n",
    "        return loaded\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        nii_files = [f for f in filenames if f.lower().endswith('.nii') or f.lower().endswith('.nii.gz')]\n",
    "        for fname in nii_files:\n",
    "            fpath = os.path.join(dirpath, fname)\n",
    "            rel = os.path.relpath(fpath, root_folder)\n",
    "            print(f\"  Loading structure: {rel}\")\n",
    "            try:\n",
    "                vol = Volume(fpath)\n",
    "                surf = vol.isosurface()\n",
    "                surf.c(color).alpha(alpha)\n",
    "                loaded.append(surf)\n",
    "            except Exception as e:\n",
    "                print(f\"  [WARN] Failed to load volume/surface: {fpath} ({e})\")\n",
    "    if not loaded:\n",
    "        print(f\"  [INFO] No NIfTI files found under {root_folder}\")\n",
    "    return loaded\n",
    "\n",
    "print(\"\\nLoading Entry Zones (LEFT)...\")\n",
    "left_entry_zone_structures = load_folder_surfaces(left_entry_zone_dir, color=(0.95, 0.65, 0.85), alpha=0.04)\n",
    "print(\"Loading Entry Zones (RIGHT)...\")\n",
    "right_entry_zone_structures = load_folder_surfaces(right_entry_zone_dir, color=(0.95, 0.75, 0.85), alpha=0.04)\n",
    "\n",
    "# STN folders (may already be deepest; recursion still safe)\n",
    "print(\"\\nLoading STN (LEFT)...\")\n",
    "left_stn_structures = load_folder_surfaces(left_stn_dir, color=\"green\", alpha=1.0)\n",
    "print(\"Loading STN (RIGHT)...\")\n",
    "right_stn_structures = load_folder_surfaces(right_stn_dir, color=\"green\", alpha=1.0)\n",
    "\n",
    "print(\"\\nLoading Obstacles...\")\n",
    "obstacle_structures = load_folder_surfaces(obstacles_dir, color=\"red\", alpha=0.7)\n",
    "\n",
    "print(\"\\nLoading Full Brain Outline...\")\n",
    "full_brain_structures = load_folder_surfaces(full_brain_dir, color=\"grey\", alpha=0.01)\n",
    "\n",
    "print(\"\\nLoading Skin Surface...\")\n",
    "# Use light skin tone color and slightly higher alpha for visibility\n",
    "skin_structures = load_folder_surfaces(skin_dir, color=\"grey\", alpha=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b851d",
   "metadata": {},
   "source": [
    "### Merge Structures\n",
    "\n",
    "Combine individual structures into single meshes for:\n",
    "- LEFT/RIGHT Entry Zones (start sampling)\n",
    "- LEFT/RIGHT STN (target sampling hemisphere-consistent)\n",
    "- Obstacles (for intersection & distance)\n",
    "- Full Brain (context outline only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f56843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Summary:\n",
      "  Left Entry Zone: yes\n",
      "  Right Entry Zone: yes\n",
      "  Left Allowed Entry Zone: yes\n",
      "  Right Allowed Entry Zone: yes\n",
      "  Left STN: yes\n",
      "  Right STN: yes\n",
      "  Obstacles: yes\n",
      "  Full Brain: yes\n",
      "  Skin: yes\n"
     ]
    }
   ],
   "source": [
    "# Merge structures into single meshes\n",
    "merged_left_entry_zone = merge(left_entry_zone_structures) if left_entry_zone_structures else None\n",
    "if merged_left_entry_zone: merged_left_entry_zone.alpha(0.04)\n",
    "\n",
    "merged_right_entry_zone = merge(right_entry_zone_structures) if right_entry_zone_structures else None\n",
    "if merged_right_entry_zone: merged_right_entry_zone.alpha(0.04)\n",
    "\n",
    "merged_allowed_left_entry_zone = merged_left_entry_zone\n",
    "merged_allowed_right_entry_zone = merged_right_entry_zone\n",
    "\n",
    "merged_left_stn = merge(left_stn_structures) if left_stn_structures else None\n",
    "merged_right_stn = merge(right_stn_structures) if right_stn_structures else None\n",
    "\n",
    "merged_obstacles = merge(obstacle_structures) if obstacle_structures else None\n",
    "if merged_obstacles: merged_obstacles.c(\"red\").alpha(0.75)\n",
    "\n",
    "merged_full_brain = merge(full_brain_structures) if full_brain_structures else None\n",
    "if merged_full_brain: merged_full_brain.c(\"grey\").alpha(0.01)\n",
    "\n",
    "merged_skin = merge(skin_structures) if skin_structures else None\n",
    "if merged_skin: merged_skin.c(\"grey\").alpha(0.02)\n",
    "\n",
    "print(\"\\nMerged Summary:\")\n",
    "print(f\"  Left Entry Zone: {'yes' if merged_left_entry_zone else 'no'}\")\n",
    "print(f\"  Right Entry Zone: {'yes' if merged_right_entry_zone else 'no'}\")\n",
    "print(f\"  Left Allowed Entry Zone: {'yes' if merged_allowed_left_entry_zone else 'no'}\")\n",
    "print(f\"  Right Allowed Entry Zone: {'yes' if merged_allowed_right_entry_zone else 'no'}\")\n",
    "print(f\"  Left STN: {'yes' if merged_left_stn else 'no'}\")\n",
    "print(f\"  Right STN: {'yes' if merged_right_stn else 'no'}\")\n",
    "print(f\"  Obstacles: {'yes' if merged_obstacles else 'no'}\")\n",
    "print(f\"  Full Brain: {'yes' if merged_full_brain else 'no'}\")\n",
    "print(f\"  Skin: {'yes' if merged_skin else 'no'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed3254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot and show the outer entry zone\n",
    "# actors1 = []\n",
    "# actors1.append(merged_allowed_left_entry_zone)\n",
    "# actors1.append(merged_allowed_right_entry_zone)\n",
    "# actors1.append(merged_skin)\n",
    "# # actors1.append(merged_full_brain)\n",
    "# show(actors1, axes=1, viewup=\"z\", title=\"Entry Zones\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236a915",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b2a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path_length(start_point, end_point):\n",
    "    \"\"\"Compute the distance between two points for the line path.\"\"\"\n",
    "    return np.linalg.norm(np.array(end_point) - np.array(start_point))\n",
    "\n",
    "\n",
    "def compute_obstacle_distance(start_point, end_point):\n",
    "    \"\"\"Compute the minimum distance from the line path to any obstacle.\"\"\"\n",
    "    if merged_obstacles is None:\n",
    "        return 0.0\n",
    "    temp_line = Line([start_point, end_point])\n",
    "    d = temp_line.distance_to(merged_obstacles)\n",
    "    if isinstance(d, (list, tuple, np.ndarray)):\n",
    "        return float(np.min(d))\n",
    "    return float(d)\n",
    "\n",
    "\n",
    "def check_intersection(start_point, end_point):\n",
    "    \"\"\"Check if the line path intersects any obstacle.\"\"\"\n",
    "    if merged_obstacles is None:\n",
    "        return False\n",
    "    intersections = merged_obstacles.intersect_with_line(start_point, end_point)\n",
    "    return intersections is not None and len(intersections) > 0\n",
    "\n",
    "\n",
    "def _closest_point_on_mesh(point, mesh):\n",
    "    \"\"\"Project a 3D point onto the closest point on a mesh surface.\"\"\"\n",
    "    if mesh is None:\n",
    "        return tuple(point)\n",
    "    try:\n",
    "        cp = mesh.closest_point(point)\n",
    "        return tuple(cp)\n",
    "    except Exception:\n",
    "        # Fallback to nearest vertex\n",
    "        verts = np.asarray(mesh.vertices)\n",
    "        if verts.size == 0:\n",
    "            return tuple(point)\n",
    "        idx = int(np.argmin(np.linalg.norm(verts - np.asarray(point), axis=1)))\n",
    "        return tuple(verts[idx])\n",
    "\n",
    "\n",
    "def project_to_surfaces(start_point, end_point, hemisphere):\n",
    "    \"\"\"Project start onto entry zone then onto skin; end onto STN for hemisphere.\"\"\"\n",
    "    # 1. project to entry zone of hemisphere\n",
    "    if hemisphere == 'left':\n",
    "        sp_entry = _closest_point_on_mesh(start_point, merged_allowed_left_entry_zone)\n",
    "        ep = _closest_point_on_mesh(end_point, merged_left_stn)\n",
    "    else:\n",
    "        sp_entry = _closest_point_on_mesh(start_point, merged_allowed_right_entry_zone)\n",
    "        ep = _closest_point_on_mesh(end_point, merged_right_stn)\n",
    "    # 2. project onto head skin surface\n",
    "    sp = _closest_point_on_mesh(sp_entry, merged_skin)\n",
    "    return sp, ep\n",
    "\n",
    "\n",
    "def sample_start_and_end():\n",
    "    \"\"\"Sample a hemisphere-consistent start (entry zone) and end (STN).\"\"\"\n",
    "    hemispheres = []\n",
    "    if merged_allowed_left_entry_zone and merged_left_stn:\n",
    "        hemispheres.append('left')\n",
    "    if merged_allowed_right_entry_zone and merged_right_stn:\n",
    "        hemispheres.append('right')\n",
    "    if not hemispheres:\n",
    "        raise RuntimeError(\"No valid hemisphere data available for sampling.\")\n",
    "    hemi = random.choice(hemispheres)\n",
    "    # Sample a random point from entry zone surface, then project to skin\n",
    "    if hemi == 'left':\n",
    "        start_entry = tuple(merged_allowed_left_entry_zone.generate_random_points(1).points[0])\n",
    "        end = tuple(merged_left_stn.generate_random_points(1).points[0])\n",
    "    else:\n",
    "        start_entry = tuple(merged_allowed_right_entry_zone.generate_random_points(1).points[0])\n",
    "        end = tuple(merged_right_stn.generate_random_points(1).points[0])\n",
    "    start = _closest_point_on_mesh(start_entry, merged_skin)\n",
    "    return hemi, start, end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d74848",
   "metadata": {},
   "source": [
    "## Cubic Bezier Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5f1df",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3023e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MIN_MM = 40.0  # min radius of curvature\n",
    "NUM_SAMPLE = 500 # number of line samples for bezier helper functions\n",
    "MAX_P1_P2_OPT_IT = 20 # max number of iterations for p1 p2 optimization\n",
    "P1_P2_OPT_TOL = 1e-2 # tolerance for p1 p2 differential evolution optimization\n",
    "\n",
    "w_obstacle = 0.9     # Weight for obstacle distance (higher = prefer safer paths)\n",
    "w_path_length = 0.1   # Weight for path length (higher = prefer shorter paths)\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "total_weight = w_obstacle + w_path_length\n",
    "w_obstacle_norm = w_obstacle / total_weight\n",
    "w_path_length_norm = w_path_length / total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a83edb",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd29ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def propose_control_points(start, end): ## random generation of alpha, beta, gamma, and direction vector\n",
    "#     start = np.array(start)\n",
    "#     end = np.array(end)\n",
    "#     d = end - start\n",
    "#     d_norm = d / np.linalg.norm(d)\n",
    "\n",
    "#     # perpendicular vector\n",
    "#     tmp = np.random.randn(3)\n",
    "#     perp = tmp - np.dot(tmp, d_norm)*d_norm\n",
    "#     perp /= np.linalg.norm(perp)\n",
    "\n",
    "#     alpha = np.random.uniform(0.1, 0.4)\n",
    "#     gamma = np.random.uniform(0.6, 0.9)\n",
    "#     beta = np.random.uniform(0, 25.0)  # mm\n",
    "\n",
    "#     P1 = start + alpha * d + beta * perp\n",
    "#     P2 = start + gamma * d - beta * perp\n",
    "\n",
    "#     return P1, P2\n",
    "\n",
    "\n",
    "def control_points_from_params_with_angle(start_point, end_point,\n",
    "                                          alpha, gamma, beta_mm, theta):\n",
    "    P0 = np.asarray(start_point, dtype=float)\n",
    "    P3 = np.asarray(end_point, dtype=float)\n",
    "    d = P3 - P0\n",
    "    d_norm = d / (np.linalg.norm(d) + 1e-9)\n",
    "\n",
    "    # build an orthonormal basis (u, v) in the plane perp to d_norm\n",
    "    if abs(d_norm[0]) < 0.9:\n",
    "        ref = np.array([1.0, 0.0, 0.0])\n",
    "    else:\n",
    "        ref = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "    u = np.cross(d_norm, ref)\n",
    "    u /= (np.linalg.norm(u) + 1e-9)\n",
    "\n",
    "    v = np.cross(d_norm, u)\n",
    "    v /= (np.linalg.norm(v) + 1e-9)\n",
    "\n",
    "    # optimized perpendicular direction\n",
    "    perp = np.cos(theta) * u + np.sin(theta) * v\n",
    "\n",
    "    P1 = P0 + alpha * d + beta_mm * perp\n",
    "    P2 = P0 + gamma * d - beta_mm * perp\n",
    "    return P1, P2\n",
    "\n",
    "\n",
    "def sample_bezier_points(start_point, control_point1, control_point2, end_point, num_samples=NUM_SAMPLE):\n",
    "    # sample points along 3d cubic bezier curve\n",
    "    P0 = np.asarray(start_point, dtype=float)\n",
    "    P1 = np.asarray(control_point1, dtype=float)\n",
    "    P2 = np.asarray(control_point2, dtype=float)\n",
    "    P3 = np.asarray(end_point, dtype=float)\n",
    "\n",
    "    t = np.linspace(0.0, 1.0, num_samples)\n",
    "    one_minus_t = 1.0 - t\n",
    "\n",
    "    pts = (\n",
    "        (one_minus_t**3)[:, None] * P0 +\n",
    "        (3 * one_minus_t**2 * t)[:, None] * P1 +\n",
    "        (3 * one_minus_t * t**2)[:, None] * P2 +\n",
    "        (t**3)[:, None] * P3\n",
    "    )\n",
    "    return pts\n",
    "\n",
    "\n",
    "def compute_obstacle_distance_bezier(start_point, end_point, control_point1, control_point2, num_samples=NUM_SAMPLE):\n",
    "    # calculate the minimum distance from the cubic bezier path to any obstacle\n",
    "    if merged_obstacles is None:\n",
    "        return 0.0\n",
    "\n",
    "    pts = sample_bezier_points(start_point, control_point1, control_point2, end_point, num_samples=num_samples)\n",
    "    curve_pts = Points(pts)\n",
    "\n",
    "    d = curve_pts.distance_to(merged_obstacles)\n",
    "    if isinstance(d, (list, tuple, np.ndarray)):\n",
    "        return float(np.min(d))\n",
    "    return float(d)\n",
    "\n",
    "\n",
    "def check_intersection_bezier(start_point, end_point, control_point1, control_point2, num_samples=NUM_SAMPLE):\n",
    "    \"\"\"\n",
    "    1. check if the cubic bezier path intersects any obstacle, and\n",
    "    2. approximates curve with short line segments and tests each segment.\n",
    "    \"\"\"\n",
    "    if merged_obstacles is None:\n",
    "        return False\n",
    "\n",
    "    pts = sample_bezier_points(start_point, control_point1, control_point2, end_point, num_samples=num_samples)\n",
    "\n",
    "    # check each segment along the curve\n",
    "    for i in range(len(pts) - 1):\n",
    "        p0 = pts[i]\n",
    "        p1 = pts[i + 1]\n",
    "        intersections = merged_obstacles.intersect_with_line(p0, p1)\n",
    "        if intersections is not None and len(intersections) > 0:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def compute_bezier_path_length(\n",
    "    start_point,\n",
    "    end_point,\n",
    "    control_point1,\n",
    "    control_point2,\n",
    "    min_radius_mm=None,\n",
    "    num_samples=NUM_SAMPLE,\n",
    "):\n",
    "    \"\"\"\n",
    "    compute length of 3d cubic bezeier curve btw start_point and end_point\n",
    "\n",
    "    calculate p1 p2 from propose_control_points helper function\n",
    "\n",
    "    \"\"\"\n",
    "    P0 = np.asarray(start_point, dtype=float)\n",
    "    P1 = np.asarray(control_point1, dtype=float)\n",
    "    P2 = np.asarray(control_point2, dtype=float)\n",
    "    P3 = np.asarray(end_point, dtype=float)\n",
    "\n",
    "    t = np.linspace(0.0, 1.0, num_samples)\n",
    "\n",
    "    def bezier_pos(t):\n",
    "        one_minus_t = 1.0 - t\n",
    "        return (\n",
    "            (one_minus_t**3)[:, None] * P0 +\n",
    "            (3 * one_minus_t**2 * t)[:, None] * P1 +\n",
    "            (3 * one_minus_t * t**2)[:, None] * P2 +\n",
    "            (t**3)[:, None] * P3\n",
    "        )\n",
    "\n",
    "    # first derivative B'(t)\n",
    "    def bezier_first_derivative(t):\n",
    "        one_minus_t = 1.0 - t\n",
    "        return (\n",
    "            (3 * one_minus_t**2)[:, None] * (P1 - P0) +\n",
    "            (6 * one_minus_t * t)[:, None] * (P2 - P1) +\n",
    "            (3 * t**2)[:, None] * (P3 - P2)\n",
    "        )\n",
    "\n",
    "    # secibd derivative B''(t)\n",
    "    def bezier_second_derivative(t):\n",
    "        return (\n",
    "            (6 * (1.0 - t))[:, None] * (P2 - 2*P1 + P0) +\n",
    "            (6 * t)[:, None] * (P3 - 2*P2 + P1)\n",
    "        )\n",
    "\n",
    "    pts = bezier_pos(t) #sample curve\n",
    "\n",
    "    # approx. length\n",
    "    diffs = np.diff(pts, axis=0)\n",
    "    segment_lengths = np.linalg.norm(diffs, axis=1)\n",
    "    length = float(np.sum(segment_lengths))\n",
    "\n",
    "    # electrode needle curvature constraint\n",
    "    if min_radius_mm is not None:\n",
    "        t_mid = t[1:-1]\n",
    "        B1 = bezier_first_derivative(t_mid)\n",
    "        B2 = bezier_second_derivative(t_mid)\n",
    "\n",
    "        # curvature k(t) = ||B'(t) x B''(t)|| / ||B'(t)||^3\n",
    "        cross = np.cross(B1, B2)\n",
    "        num = np.linalg.norm(cross, axis=1)\n",
    "        denom = np.linalg.norm(B1, axis=1)**3\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            curvature = np.where(denom > 0, num / denom, 0.0)\n",
    "\n",
    "        # radius of curvature R(t) = 1 / k(t) --> if straight, R(t) = inf\n",
    "        radius = np.where(curvature > 0, 1.0 / curvature, np.inf)\n",
    "\n",
    "        min_radius_on_curve = np.min(radius)\n",
    "\n",
    "        if min_radius_on_curve < min_radius_mm:\n",
    "            # print(f\"Curvature constraint violated: minimum radius along curve \")\n",
    "            # print(f\"is {min_radius_on_curve:.3f} mm, required >= {min_radius_mm:.3f} mm.\")\n",
    "            return None \n",
    "\n",
    "    return length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902625a",
   "metadata": {},
   "source": [
    "#### Control Point (P1 P2) Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68dc1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cp_objective(params, start_point, end_point):\n",
    "    alpha, gamma, beta_mm, theta = params\n",
    "\n",
    "    P1, P2 = control_points_from_params_with_angle(\n",
    "        start_point, end_point, alpha, gamma, beta_mm, theta\n",
    "    )\n",
    "\n",
    "    raw_length = compute_bezier_path_length(\n",
    "        start_point=start_point,\n",
    "        end_point=end_point,\n",
    "        control_point1=P1,\n",
    "        control_point2=P2,\n",
    "        min_radius_mm=R_MIN_MM,\n",
    "    )\n",
    "    if raw_length is None:\n",
    "        return 1e10\n",
    "\n",
    "    # handle scalar vs tuple/list return\n",
    "    min_radius = None\n",
    "    if isinstance(raw_length, (tuple, list, np.ndarray)):\n",
    "        path_length = float(raw_length[0])\n",
    "        if len(raw_length) > 1:\n",
    "            min_radius = raw_length[1]\n",
    "    else:\n",
    "        path_length = float(raw_length)\n",
    "\n",
    "    if min_radius is not None:\n",
    "        try:\n",
    "            if float(min_radius) < float(R_MIN_MM):\n",
    "                return 1e10\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "    if check_intersection_bezier(start_point, end_point, P1, P2, num_samples=NUM_SAMPLE):\n",
    "        return 1e10\n",
    "\n",
    "    obstacle_dist_raw = compute_obstacle_distance_bezier(\n",
    "        start_point, end_point, P1, P2, num_samples=NUM_SAMPLE\n",
    "    )\n",
    "\n",
    "    if isinstance(obstacle_dist_raw, (list, tuple, np.ndarray)): #obj dist should be scalar\n",
    "        if len(obstacle_dist_raw) == 0:\n",
    "            obstacle_dist = 0.0\n",
    "        else:\n",
    "            obstacle_dist = float(np.min(obstacle_dist_raw))\n",
    "    else:\n",
    "        obstacle_dist = float(obstacle_dist_raw)\n",
    "    \n",
    "    if max_obstacle_dist is not None and max_obstacle_dist > 0:\n",
    "        norm_obstacle_dist = obstacle_dist / max_obstacle_dist\n",
    "    else:\n",
    "        norm_obstacle_dist = obstacle_dist / 8\n",
    "\n",
    "    if max_path_length is not None and max_path_length > 0:\n",
    "        norm_path_length = path_length / max_path_length\n",
    "    else:\n",
    "        norm_path_length = path_length / 105\n",
    "\n",
    "    objective = -w_obstacle_norm * norm_obstacle_dist + w_path_length_norm * norm_path_length\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def control_points_from_params_with_angle(start_point, end_point,\n",
    "                                          alpha, gamma, beta_mm, theta):\n",
    "    P0 = np.asarray(start_point, dtype=float)\n",
    "    P3 = np.asarray(end_point, dtype=float)\n",
    "    d = P3 - P0\n",
    "    d_norm = d / (np.linalg.norm(d) + 1e-9)\n",
    "\n",
    "    # build an orthonormal basis in the plane perp w d_norm\n",
    "    if abs(d_norm[0]) < 0.9:\n",
    "        ref = np.array([1.0, 0.0, 0.0])\n",
    "    else:\n",
    "        ref = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "    u = np.cross(d_norm, ref)\n",
    "    u /= (np.linalg.norm(u) + 1e-9)\n",
    "\n",
    "    v = np.cross(d_norm, u)\n",
    "    v /= (np.linalg.norm(v) + 1e-9)\n",
    "\n",
    "    # find perpendicular direction given theta\n",
    "    perp = np.cos(theta) * u + np.sin(theta) * v\n",
    "\n",
    "    # calculate P1 and P2 from alpha, beta, gamma, and perp (from theta)\n",
    "    P1 = P0 + alpha * d + beta_mm * perp\n",
    "    P2 = P0 + gamma * d - beta_mm * perp\n",
    "\n",
    "    return P1, P2\n",
    "\n",
    "\n",
    "def optimize_control_points(start_point, end_point):\n",
    "    \"\"\"\n",
    "    for a fixed start/end optimize (alpha, gamma, beta_mm, theta) to get best P1 P2.\n",
    "\n",
    "    alpha: location of P1 along chord [0, 1]\n",
    "    gamma: location of P2 along chord [0, 1]\n",
    "    beta_mm: lateral offset magnitude in mm\n",
    "    theta: angle (radians) selecting direction in the perp plane\n",
    "    \"\"\"\n",
    "    bounds = [\n",
    "        (0.1, 0.5), # alpha\n",
    "        (0.5, 0.9), # gamma\n",
    "        (0.0, 25.0), # beta_mm (sideways offset)\n",
    "        (0.0, 2.0 * np.pi) # theta (angle around the axis)\n",
    "    ]\n",
    "\n",
    "    result = differential_evolution(\n",
    "        inner_cp_objective,\n",
    "        bounds=bounds,\n",
    "        args=(start_point, end_point),\n",
    "        maxiter=MAX_P1_P2_OPT_IT,\n",
    "        tol=P1_P2_OPT_TOL,\n",
    "        polish=False,\n",
    "        disp=False\n",
    "    )\n",
    "\n",
    "    alpha_opt, gamma_opt, beta_opt, theta_opt = result.x\n",
    "    P1_opt, P2_opt = control_points_from_params_with_angle(\n",
    "        start_point, end_point,\n",
    "        alpha_opt, gamma_opt, beta_opt, theta_opt\n",
    "    )\n",
    "    return P1_opt, P2_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c6347",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9c87d",
   "metadata": {},
   "source": [
    "### Path Generation and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33158c07",
   "metadata": {},
   "source": [
    "Generate random paths from brain surface to STN and evaluate them:\n",
    "- **Orange lines**: Failed paths (intersect obstacles)\n",
    "- **Yellow lines**: Successful but suboptimal paths\n",
    "- **Green line**: Optimal path (maximum distance from obstacles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746bda9b",
   "metadata": {},
   "source": [
    "**Optimization Algorithm**\n",
    "\n",
    "Runs until finding a successful path and after a minimum of `min_attempts`.\n",
    "\n",
    "Chooses a **random location** from the viable brain surface region and the STN of the corresponding hemisphere. \n",
    "\n",
    "For each plot, the distance from obstacles is saved. The \"best\" path is determined using the highest distance to obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ef872cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config for Monte Carlo\n",
    "# Monte Carlo path generation parameters\n",
    "max_attempts = 2000\n",
    "min_successful_attempts = 20\n",
    "\n",
    "# Line width configuration (for visualization)\n",
    "BEST_PATH_WIDTH = 6\n",
    "SUBOPTIMAL_PATH_WIDTH = 4\n",
    "FAILED_PATH_WIDTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: hemisphere=left start=(np.float64(24.25), np.float64(135.75), np.float64(56.25)) end=(np.float32(108.06412), np.float32(133.00252), np.float32(74.0))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (1/20) - Obstacle Distance: 3.333 Path Length: 85.717\n",
      "Attempt 2: hemisphere=left start=(np.float64(208.25), np.float64(102.0), np.float64(81.75)) end=(np.float32(106.0), np.float32(130.1359), np.float32(72.53741))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (2/20) - Obstacle Distance: 2.941 Path Length: 107.246\n",
      "Attempt 3: hemisphere=right start=(np.float64(57.75), np.float64(57.25), np.float64(99.75)) end=(np.float32(106.98612), np.float32(129.25), np.float32(84.253044))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (3/20) - Obstacle Distance: 0.920 Path Length: 88.750\n",
      "Attempt 4: hemisphere=left start=(np.float64(182.36740112304688), np.float64(72.36740112304688), np.float64(48.75)) end=(np.float32(109.21791), np.float32(129.71791), np.float32(70.87031))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (4/20) - Obstacle Distance: 2.130 Path Length: 99.418\n",
      "Attempt 5: hemisphere=left start=(np.float64(61.5), np.float64(54.25), np.float64(56.25)) end=(np.float32(108.07383), np.float32(130.95578), np.float32(70.45578))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (5/20) - Obstacle Distance: 2.522 Path Length: 92.518\n",
      "Attempt 6: hemisphere=left start=(np.float64(117.49640655517578), np.float64(49.75), np.float64(49.5)) end=(np.float32(107.14195), np.float32(129.68333), np.float32(73.183334))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (6/20) - Obstacle Distance: 1.165 Path Length: 84.363\n",
      "Attempt 7: hemisphere=left start=(np.float64(179.25), np.float64(116.25), np.float64(17.5)) end=(np.float32(106.646904), np.float32(129.69276), np.float32(71.41034))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (7/20) - Obstacle Distance: 3.789 Path Length: 91.438\n",
      "Attempt 8: hemisphere=right start=(np.float64(90.0), np.float64(105.75), np.float64(148.25)) end=(np.float32(106.27541), np.float32(131.5254), np.float32(82.86213))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (8/20) - Obstacle Distance: 4.972 Path Length: 72.150\n",
      "Attempt 9: hemisphere=right start=(np.float64(123.0), np.float64(50.5), np.float64(111.0)) end=(np.float32(109.25), np.float32(131.07492), np.float32(84.24506))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (9/20) - Obstacle Distance: 2.658 Path Length: 88.664\n",
      "Attempt 10: hemisphere=left start=(np.float64(200.75), np.float64(84.0), np.float64(81.75)) end=(np.float32(106.433334), np.float32(129.64308), np.float32(73.076416))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (10/20) - Obstacle Distance: 2.135 Path Length: 107.035\n",
      "Attempt 11: hemisphere=left start=(np.float64(119.75), np.float64(48.25), np.float64(52.5)) end=(np.float32(109.25), np.float32(132.3902), np.float32(72.88866))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (11/20) - Obstacle Distance: 1.632 Path Length: 89.979\n",
      "Attempt 12: hemisphere=left start=(np.float64(92.25), np.float64(56.5), np.float64(39.0)) end=(np.float32(109.25), np.float32(132.3187), np.float32(73.01633))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (12/20) - Obstacle Distance: 3.375 Path Length: 85.318\n",
      "Attempt 13: hemisphere=right start=(np.float64(45.0), np.float64(77.25), np.float64(116.75)) end=(np.float32(106.75), np.float32(131.8579), np.float32(83.452385))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doubl\\AppData\\Local\\Temp\\ipykernel_33052\\2291775572.py:171: RuntimeWarning: divide by zero encountered in divide\n",
      "  radius = np.where(curvature > 0, 1.0 / curvature, np.inf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (13/20) - Obstacle Distance: 5.561 Path Length: 88.908\n",
      "Attempt 14: hemisphere=left start=(np.float64(203.0), np.float64(130.61509704589844), np.float64(37.5)) end=(np.float32(108.46041), np.float32(129.25), np.float32(70.89402))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  Skipping path: violates curvature constraint\n",
      "Attempt 15: hemisphere=right start=(np.float64(105.75), np.float64(49.0), np.float64(107.25)) end=(np.float32(106.29595), np.float32(129.63644), np.float32(84.182396))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (14/20) - Obstacle Distance: 3.901 Path Length: 85.752\n",
      "Attempt 16: hemisphere=right start=(np.float64(169.5), np.float64(61.0), np.float64(110.25)) end=(np.float32(108.35289), np.float32(129.51784), np.float32(86.517845))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  FAIL - Curve intersects obstacles\n",
      "Attempt 17: hemisphere=right start=(np.float64(43.5), np.float64(69.25), np.float64(106.5)) end=(np.float32(107.1783), np.float32(131.51857), np.float32(84.90973))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (15/20) - Obstacle Distance: 5.720 Path Length: 91.832\n",
      "Attempt 18: hemisphere=right start=(np.float64(55.5), np.float64(53.5), np.float64(88.5)) end=(np.float32(107.629745), np.float32(130.07272), np.float32(82.80703))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  Skipping path: violates curvature constraint\n",
      "Attempt 19: hemisphere=left start=(np.float64(191.0), np.float64(72.75), np.float64(63.75)) end=(np.float32(106.6065), np.float32(131.75525), np.float32(72.64874))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (16/20) - Obstacle Distance: 1.019 Path Length: 106.535\n",
      "Attempt 20: hemisphere=right start=(np.float64(132.75), np.float64(78.0), np.float64(141.5)) end=(np.float32(109.25), np.float32(131.5854), np.float32(83.39831))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (17/20) - Obstacle Distance: 3.187 Path Length: 84.209\n",
      "Attempt 21: hemisphere=right start=(np.float64(17.5), np.float64(100.59756088256836), np.float64(93.09756088256836)) end=(np.float32(109.234566), np.float32(132.69357), np.float32(82.484566))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (18/20) - Obstacle Distance: 2.188 Path Length: 101.653\n",
      "Attempt 22: hemisphere=left start=(np.float64(88.5), np.float64(90.75), np.float64(13.0)) end=(np.float32(108.422585), np.float32(133.57741), np.float32(72.912796))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (19/20) - Obstacle Distance: 3.102 Path Length: 78.351\n",
      "Attempt 23: hemisphere=right start=(np.float64(90.0), np.float64(68.25), np.float64(131.0)) end=(np.float32(109.25), np.float32(130.20161), np.float32(84.75371))\n",
      "[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\n",
      "  SUCCESS (20/20) - Obstacle Distance: 1.812 Path Length: 81.501\n"
     ]
    }
   ],
   "source": [
    "## Run Monte Carlo sampling\n",
    "\n",
    "successful_attempts = []  # Store (hemisphere, start_point, end_point, obstacle_distance, path_length) tuples\n",
    "failed_attempts = []      # Store (hemisphere, start_point, end_point, obstacle_distance(=0 for fail), path_length)\n",
    "failed_lines = []\n",
    "\n",
    "# Generate and evaluate hemisphere-consistent bezier paths\n",
    "for attempt in range(max_attempts):\n",
    "    if len(successful_attempts) >= min_successful_attempts:\n",
    "        break\n",
    "\n",
    "    hemi, start_point, end_point = sample_start_and_end()\n",
    "    print(f\"Attempt {attempt+1}: hemisphere={hemi} start={start_point} end={end_point}\")\n",
    "\n",
    "    # Generate control points for cubic bezier curve\n",
    "    P1, P2 = optimize_control_points(start_point, end_point)\n",
    "    print(\"[OPTIMIZE] Obtained optimal P1, P2 for startpoint and end point\")\n",
    "    # Compute path length with curvature constraint\n",
    "    path_len = compute_bezier_path_length(\n",
    "        start_point=start_point,\n",
    "        end_point=end_point,\n",
    "        control_point1=P1,\n",
    "        control_point2=P2,\n",
    "        min_radius_mm=R_MIN_MM,\n",
    "    )\n",
    "    \n",
    "    if path_len is None:  # skip paths that violate curvature (too sharp bend)\n",
    "        print(f\"  Skipping path: violates curvature constraint\")\n",
    "        continue\n",
    "\n",
    "    # Check for intersection if we have obstacles\n",
    "    if merged_obstacles:\n",
    "        if not check_intersection_bezier(start_point, end_point, P1, P2, num_samples=100):\n",
    "            # Compute metrics\n",
    "            obstacle_dist = compute_obstacle_distance_bezier(start_point, end_point, P1, P2)\n",
    "            successful_attempts.append((hemi, start_point, end_point, P1, P2, obstacle_dist, path_len))\n",
    "            print(f\"  SUCCESS ({len(successful_attempts)}/{min_successful_attempts}) - Obstacle Distance: {obstacle_dist:.3f} Path Length: {path_len:.3f}\")\n",
    "        else:\n",
    "            pts = sample_bezier_points(start_point, P1, P2, end_point, num_samples=100)\n",
    "            failed_line = Line(pts).c(\"orange\").alpha(0.3).lw(FAILED_PATH_WIDTH)\n",
    "            failed_lines.append(failed_line)\n",
    "            failed_attempts.append((hemi, start_point, end_point, P1, P2, 0.0, path_len))\n",
    "            print(\"  FAIL - Curve intersects obstacles\")\n",
    "    else:\n",
    "        obstacle_dist = 0.0\n",
    "        successful_attempts.append((hemi, start_point, end_point, P1, P2, obstacle_dist, path_len))\n",
    "        print(f\"  SUCCESS (no obstacles) Path Length: {path_len:.3f}\")\n",
    "else:\n",
    "    print(f\"Warning: Only found {len(successful_attempts)} non-intersecting curves after {max_attempts} attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6a906",
   "metadata": {},
   "source": [
    "### Select Optimal Path\n",
    "\n",
    "Find the best path among successful attempts by maximizing distance from obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b30bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best path: hemisphere=right obstacle_dist=5.720 path_len=91.832\n",
      "Suboptimal path 1: hemi=right obstacle_dist=5.561 path_len=88.908\n",
      "Suboptimal path 2: hemi=right obstacle_dist=4.972 path_len=72.150\n",
      "Suboptimal path 3: hemi=right obstacle_dist=3.901 path_len=85.752\n",
      "Suboptimal path 4: hemi=left obstacle_dist=3.789 path_len=91.438\n",
      "Suboptimal path 5: hemi=left obstacle_dist=3.375 path_len=85.318\n",
      "Suboptimal path 6: hemi=left obstacle_dist=3.333 path_len=85.717\n",
      "Suboptimal path 7: hemi=right obstacle_dist=3.187 path_len=84.209\n",
      "Suboptimal path 8: hemi=left obstacle_dist=3.102 path_len=78.351\n",
      "Suboptimal path 9: hemi=left obstacle_dist=2.941 path_len=107.246\n",
      "Suboptimal path 10: hemi=right obstacle_dist=2.658 path_len=88.664\n",
      "\n",
      "Total successful paths:  20\n"
     ]
    }
   ],
   "source": [
    "# Select best path (maximum obstacle distance; tie-breaker shorter path length)\n",
    "SUBOPTIMAL_PATHS_TO_DISPLAY = 10\n",
    "\n",
    "best_path = None\n",
    "suboptimal_lines = []\n",
    "selected_hemisphere = None\n",
    "\n",
    "if successful_attempts:\n",
    "    # Sort: first by obstacle distance desc, then by path length asc\n",
    "    successful_attempts.sort(key=lambda x: (-x[5], x[6]))\n",
    "\n",
    "    best_hemi, best_start, best_end, best_P1, best_P2, best_obstacle_dist, best_path_len = successful_attempts[0]\n",
    "    best_pts = sample_bezier_points(best_start, best_P1, best_P2, best_end, num_samples=100)\n",
    "    best_path = Line(best_pts).c(\"green\").lw(BEST_PATH_WIDTH)\n",
    "    selected_hemisphere = best_hemi\n",
    "    print(f\"\\nBest path: hemisphere={best_hemi} obstacle_dist={best_obstacle_dist:.3f} path_len={best_path_len:.3f}\")\n",
    "\n",
    "    s = 1\n",
    "    for hemi, start_pt, end_pt, P1, P2, obstacle_dist, path_len in successful_attempts[1:]:\n",
    "        if s > SUBOPTIMAL_PATHS_TO_DISPLAY:\n",
    "            break\n",
    "        \n",
    "        pts = sample_bezier_points(start_pt, P1, P2, end_pt, num_samples=100)\n",
    "        suboptimal_line = Line(pts).c(\"yellow\").alpha(0.3).lw(SUBOPTIMAL_PATH_WIDTH)\n",
    "        suboptimal_lines.append(suboptimal_line)\n",
    "        print(f\"Suboptimal path {s}: hemi={hemi} obstacle_dist={obstacle_dist:.3f} path_len={path_len:.3f}\")\n",
    "        \n",
    "        s += 1\n",
    "else:\n",
    "    print(\"No successful paths found!\")\n",
    "\n",
    "print(\"\\nTotal successful paths: \", len(successful_attempts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6419b423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Monte Carlo bezier paths (20 success, 1 fail) to monte_carlo_bezier_paths.csv\n"
     ]
    }
   ],
   "source": [
    "## Save Monte Carlo bezier path coordinates to file (success + fail + best flag)\n",
    "output_file = \"monte_carlo_bezier_paths.csv\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"hemisphere,start_x,start_y,start_z,end_x,end_y,end_z,p1_x,p1_y,p1_z,p2_x,p2_y,p2_z,obstacle_distance,path_length,status,is_best\\n\")\n",
    "    # Successful attempts are already sorted (best first) after selection step\n",
    "    for idx, (hemi, start_pt, end_pt, P1, P2, obstacle_dist, path_len) in enumerate(successful_attempts):\n",
    "        is_best = 1 if idx == 0 else 0\n",
    "        f.write(\n",
    "            f\"{hemi},{start_pt[0]},{start_pt[1]},{start_pt[2]},{end_pt[0]},{end_pt[1]},{end_pt[2]},{P1[0]},{P1[1]},{P1[2]},{P2[0]},{P2[1]},{P2[2]},{obstacle_dist},{path_len},success,{is_best}\\n\"\n",
    "        )\n",
    "    # Failed attempts\n",
    "    for hemi, start_pt, end_pt, P1, P2, obstacle_dist, path_len in failed_attempts:\n",
    "        f.write(\n",
    "            f\"{hemi},{start_pt[0]},{start_pt[1]},{start_pt[2]},{end_pt[0]},{end_pt[1]},{end_pt[2]},{P1[0]},{P1[1]},{P1[2]},{P2[0]},{P2[1]},{P2[2]},{obstacle_dist},{path_len},fail,0\\n\"\n",
    "        )\n",
    "print(f\"Saved Monte Carlo bezier paths ({len(successful_attempts)} success, {len(failed_attempts)} fail) to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8b522",
   "metadata": {},
   "source": [
    "## 3. Weighted Sum + Mono-Criteria Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4eb6cd",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Set weights and optimization parameters:\n",
    "- `w_obstacle`: Weight for obstacle distance (maximize)\n",
    "- `w_path_length`: Weight for path length (minimize)\n",
    "- Weights are normalized automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2cc3eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function weights:\n",
      "  Obstacle distance: 0.900\n",
      "  Path length: 0.100\n"
     ]
    }
   ],
   "source": [
    "# Weights for multi-objective optimization (easily configurable)\n",
    "w_obstacle = 0.9     # Weight for obstacle distance (higher = prefer safer paths)\n",
    "w_path_length = 0.1   # Weight for path length (higher = prefer shorter paths)\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "total_weight = w_obstacle + w_path_length\n",
    "w_obstacle_norm = w_obstacle / total_weight\n",
    "w_path_length_norm = w_path_length / total_weight\n",
    "\n",
    "print(f\"Objective function weights:\\n  Obstacle distance: {w_obstacle_norm:.3f}\\n  Path length: {w_path_length_norm:.3f}\")\n",
    "\n",
    "# Mono-criteria optimization parameters\n",
    "initial_point_attempts = 50\n",
    "opt_max_iterations = 20\n",
    "opt_tolerance = 1e-6  # default: 1e-6, applied as xatol and fatol\n",
    "\n",
    "# Hemisphere lock for optimization (set later when picking x0)\n",
    "opt_hemisphere = None\n",
    "\n",
    "# Number of best Monte Carlo paths to use as initial conditions\n",
    "n_initial = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ac81b",
   "metadata": {},
   "source": [
    "### Weighted Sum Objective Function\n",
    "\n",
    "Combines both objectives (obstacle distance and path length) into a single scalar value for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8c69c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with P1P2 optimization\n",
    "\n",
    "max_obstacle_dist = None\n",
    "max_path_length = None\n",
    "\n",
    "last_eval = {\n",
    "    \"x\": None,\n",
    "    \"start\": None,\n",
    "    \"end\": None,\n",
    "    \"P1\": None,\n",
    "    \"P2\": None,\n",
    "    \"path_points\": None,\n",
    "    \"objective\": None,\n",
    "}\n",
    "\n",
    "all_evals = []\n",
    "\n",
    "def weighted_sum_objective(x):\n",
    "    \"\"\"\n",
    "    Weighted sum objective function for optimization (cubic Bzier).\n",
    "    For each candidate start/end, first optimizes P1/P2 (curve shape),\n",
    "    then evaluates the global objective.\n",
    "    \"\"\"\n",
    "    global opt_hemisphere, last_eval, all_evals\n",
    "\n",
    "    start_guess = tuple(x[:3])\n",
    "    end_guess   = tuple(x[3:])\n",
    "\n",
    "    if opt_hemisphere is None:\n",
    "        opt_hemisphere = 'left' if merged_left_entry_zone and merged_left_stn else 'right'\n",
    "\n",
    "    start_point, end_point = project_to_surfaces(start_guess, end_guess, opt_hemisphere)\n",
    "\n",
    "    P1, P2 = optimize_control_points(start_point, end_point)\n",
    "\n",
    "    path_length = compute_bezier_path_length(\n",
    "        start_point=start_point,\n",
    "        end_point=end_point,\n",
    "        control_point1=P1,\n",
    "        control_point2=P2,\n",
    "        min_radius_mm=R_MIN_MM,\n",
    "    )\n",
    "    if path_length is None:\n",
    "        return 1e10\n",
    "\n",
    "    if check_intersection_bezier(start_point, end_point, P1, P2):\n",
    "        return 1e10\n",
    "\n",
    "    obstacle_dist = compute_obstacle_distance_bezier(start_point, end_point, P1, P2)\n",
    "\n",
    "    if max_obstacle_dist is not None and max_obstacle_dist > 0:\n",
    "        norm_obstacle_dist = obstacle_dist / max_obstacle_dist\n",
    "    else:\n",
    "        norm_obstacle_dist = obstacle_dist / 8\n",
    "\n",
    "    if max_path_length is not None and max_path_length > 0:\n",
    "        norm_path_length = path_length / max_path_length\n",
    "    else:\n",
    "        norm_path_length = path_length / 105\n",
    "\n",
    "    objective = -w_obstacle_norm * norm_obstacle_dist + w_path_length_norm * norm_path_length\n",
    "\n",
    "    path_points = sample_bezier_points(start_point, P1, P2, end_point, num_samples=NUM_SAMPLE)\n",
    "\n",
    "    last_eval = {\n",
    "        \"x\": x.copy(),\n",
    "        \"start\": start_point,\n",
    "        \"end\": end_point,\n",
    "        \"P1\": P1,\n",
    "        \"P2\": P2,\n",
    "        \"path_points\": path_points,\n",
    "        \"objective\": objective,\n",
    "    }\n",
    "    all_evals.append(last_eval.copy())\n",
    "\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1d2ba",
   "metadata": {},
   "source": [
    "### Estimate Normalization Constants\n",
    "\n",
    "Sample a few random paths to estimate typical ranges for obstacle distance and path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e6c45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Option 1: Sample random paths to estimate normalization constants\n",
    "# ESTIMATION_SAMPLES = 100\n",
    "\n",
    "# print(\"Estimating normalization constants from random samples...\")\n",
    "# sample_obstacle_dists = []\n",
    "# sample_path_lengths = []\n",
    "\n",
    "# for _ in range(ESTIMATION_SAMPLES):\n",
    "#     print(f\"Sampling path {_+1}/{ESTIMATION_SAMPLES}...\")\n",
    "#     hemi, start, end = sample_start_and_end()\n",
    "#     if not check_intersection(start, end):\n",
    "#         obstacle_dist = compute_obstacle_distance(start, end)\n",
    "#         path_length = compute_path_length(start, end)\n",
    "#         sample_obstacle_dists.append(obstacle_dist)\n",
    "#         sample_path_lengths.append(path_length)\n",
    "#         # print(f\"  obstacle_dist={obstacle_dist:.3f} path_len={path_length:.3f}\")\n",
    "#     else:\n",
    "#         print(\"  Sampled path intersects obstacles, skipping...\")\n",
    "\n",
    "# if sample_obstacle_dists:\n",
    "#     max_obstacle_dist = max(sample_obstacle_dists)\n",
    "#     max_path_length = max(sample_path_lengths)\n",
    "#     print(f\"Estimated max obstacle distance: {max_obstacle_dist:.2f}\")\n",
    "#     print(f\"Estimated max path length: {max_path_length:.2f}\")\n",
    "# else:\n",
    "#     print(\"Warning: No valid paths found for normalization, using defaults\")\n",
    "#     max_obstacle_dist = 8\n",
    "#     max_path_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7329effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OPTION 2: Use Monte Carlo results for normalization (if available)\n",
    "# if successful_attempts:\n",
    "#     print(\"\\nUsing Monte Carlo results for normalization...\")\n",
    "#     mc_obstacle_dists = [x[5] for x in successful_attempts]  # obstacle_dist is at index 5 for bezier\n",
    "#     mc_path_lengths = [x[6] for x in successful_attempts]    # path_length is at index 6 for bezier\n",
    "#     max_obstacle_dist = max(mc_obstacle_dists)\n",
    "#     max_path_length = max(mc_path_lengths)\n",
    "#     print(f\"Max obstacle distance from Monte Carlo: {max_obstacle_dist:.2f}\")\n",
    "#     print(f\"Max path length from Monte Carlo: {max_path_length:.2f}\")\n",
    "# else:\n",
    "#     print(\"\\nNo Monte Carlo results available for normalization, using defaults\")\n",
    "#     max_obstacle_dist = 8\n",
    "#     max_path_length = 105\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1e48df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 3: Set Manually\n",
    "max_obstacle_dist = 8\n",
    "max_path_length = 105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52aacb",
   "metadata": {},
   "source": [
    "### Set Initial Path for Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3768a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OPTION 1: Find first feasible initial point from random sampling\n",
    "# print(\"\\nFinding feasible initial point...\")\n",
    "# x0 = None\n",
    "# for attempt in range(initial_point_attempts):\n",
    "#     hemi, start, end = sample_start_and_end()\n",
    "#     if not check_intersection(start, end):\n",
    "#         x0 = np.concatenate([start, end])\n",
    "#         opt_hemisphere = hemi  # lock hemisphere for optimization\n",
    "#         print(f\"Found feasible starting point after {attempt+1} attempts (hemi={hemi})\")\n",
    "#         print(f\"  Start: {start}\")\n",
    "#         print(f\"  End: {end}\")\n",
    "#         break\n",
    "\n",
    "# if x0 is None:\n",
    "#     print(\"Warning: Could not find feasible starting point, using last sampled anyway\")\n",
    "#     hemi, start, end = sample_start_and_end()\n",
    "#     x0 = np.concatenate([start, end])\n",
    "#     opt_hemisphere = hemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24480db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting initial conditions from best Monte Carlo paths...\n",
      "  Using 5 initial path(s) from Monte Carlo results\n"
     ]
    }
   ],
   "source": [
    "## OPTION 2: Select best Monte Carlo path as starting point(s)\n",
    "if successful_attempts:\n",
    "    print(\"\\nSelecting initial conditions from best Monte Carlo paths...\")\n",
    "    # successful_attempts is already sorted earlier (best first)\n",
    "    take = min(n_initial, len(successful_attempts))\n",
    "    initial_paths = successful_attempts[:take]\n",
    "    \n",
    "    print(f\"  Using {take} initial path(s) from Monte Carlo results\")\n",
    "    \n",
    "    # Ensure initial_paths are not all from the same hemisphere\n",
    "    hemis = [h for h, *_ in initial_paths[:take]]\n",
    "    \n",
    "    if len(set(hemis)) == 1:\n",
    "        target_hemi = 'left' if hemis[0] == 'right' else 'right'\n",
    "        print(f\"  Detected single-hemisphere initials ({hemis[0]}). Picking one from {target_hemi} hemi in successful_attempts...\")\n",
    "\n",
    "        # Find first successful attempt from the opposite hemisphere beyond the first 'take'\n",
    "        replacement = next((rec for rec in successful_attempts[take:] if rec[0] == target_hemi), None)\n",
    "\n",
    "        if replacement:\n",
    "            initial_paths[-1] = replacement\n",
    "            print(\"  Replaced one initial path with other-hemisphere entry from successful_attempts.\")\n",
    "        else:\n",
    "            print(\"  Warning: No other-hemisphere entry found in successful_attempts; keeping originals.\")\n",
    "    # Update selected hemisphere preview from the first initial path\n",
    "    selected_hemisphere = initial_paths[0][0]\n",
    "else:\n",
    "    raise RuntimeError(\"No successful Monte Carlo paths available for optimization initialization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2705d",
   "metadata": {},
   "source": [
    "### Mono-criteria optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d484dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_multistart_bezier(method_name, options):\n",
    "    \"\"\"Run chosen optimization method over all initial_paths and return best record.\n",
    "    \n",
    "    Updated for Bezier curves with control point optimization.\n",
    "\n",
    "    Returns:\n",
    "      best_record, records_list\n",
    "    Prints per-start info plus total elapsed time and summed iterations across starts.\n",
    "    \"\"\"\n",
    "    if not initial_paths:\n",
    "        raise RuntimeError(\"initial_paths is empty. Ensure Monte Carlo step ran and initial paths were selected.\")\n",
    "\n",
    "    best = None\n",
    "    records = []\n",
    "    total_time = 0.0\n",
    "    total_iterations = 0\n",
    "\n",
    "    for idx, (hemi, start, end, P1_init, P2_init, obst, plen) in enumerate(initial_paths, start=1):\n",
    "        print(f\"\\n[{method_name} {idx}/{len(initial_paths)}] hemi={hemi}\")\n",
    "        global opt_hemisphere\n",
    "        opt_hemisphere = hemi  # hemisphere locking\n",
    "        x0 = np.concatenate([start, end])\n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        res = minimize(weighted_sum_objective, x0, method=method_name, options=options)\n",
    "        \n",
    "        elapsed = time.perf_counter() - t0\n",
    "        iters = getattr(res, 'nit', getattr(res, 'nfev', 0)) or 0\n",
    "        total_time += elapsed\n",
    "        total_iterations += iters\n",
    "\n",
    "        raw_start = tuple(res.x[:3])\n",
    "        raw_end = tuple(res.x[3:])\n",
    "        opt_start, opt_end = project_to_surfaces(raw_start, raw_end, opt_hemisphere)\n",
    "        opt_obj = float(res.fun)\n",
    "        \n",
    "        # Optimize control points for the final path\n",
    "        P1_opt, P2_opt = optimize_control_points(opt_start, opt_end)\n",
    "        \n",
    "        # Compute bezier metrics\n",
    "        opt_obst = compute_obstacle_distance_bezier(opt_start, opt_end, P1_opt, P2_opt)\n",
    "        opt_len = compute_bezier_path_length(opt_start, opt_end, P1_opt, P2_opt, min_radius_mm=R_MIN_MM)\n",
    "        \n",
    "        # Create bezier curve for visualization\n",
    "        path_points = sample_bezier_points(opt_start, P1_opt, P2_opt, opt_end, num_samples=NUM_SAMPLE)\n",
    "        if method_name == 'Nelder-Mead':\n",
    "            opt_line = Line(path_points).c(\"cyan\").lw(10)\n",
    "        elif method_name == 'Powell':\n",
    "            opt_line = Line(path_points).c(\"magenta\").lw(10)\n",
    "        elif method_name == 'COBYLA':\n",
    "            opt_line = Line(path_points).c(\"blue\").lw(10)\n",
    "        else:\n",
    "            opt_line = Line(path_points).c(\"purple\").lw(10)\n",
    "\n",
    "        rec = {\n",
    "            'method': method_name,\n",
    "            'hemi': hemi,\n",
    "            'start': opt_start,\n",
    "            'end': opt_end,\n",
    "            'P1': P1_opt,\n",
    "            'P2': P2_opt,\n",
    "            'objective': opt_obj,\n",
    "            'obstacle_distance': opt_obst,\n",
    "            'path_length': opt_len,\n",
    "            'line': opt_line,\n",
    "            'path_points': path_points,\n",
    "            'result': res,\n",
    "            'elapsed': elapsed,\n",
    "            'iterations': iters\n",
    "        }\n",
    "        records.append(rec)\n",
    "        if best is None or opt_obj < best['objective']:\n",
    "            best = rec\n",
    "        print(f\"  Objective: {opt_obj:.6f}  ObstDist: {opt_obst:.3f}  PathLen: {opt_len:.3f}\")\n",
    "        print(f\"  Elapsed: {elapsed:.3f}s  Iterations: {iters}\")\n",
    "\n",
    "    print(f\"\\n[{method_name} Summary] Total time: {total_time:.3f}s  Total iterations: {total_iterations}\")\n",
    "    return best, records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f55ed6",
   "metadata": {},
   "source": [
    "### Run Mono-Criteria Optimization\n",
    "\n",
    "Use a mono-criteria optimization algorithm to optimize the weighted sum objective. \n",
    "\n",
    "Start from a set of initial paths and repeats for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "671da04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZATION_METHOD = 'COBYLA'  # Choose from 'Nelder-Mead', 'Powell', 'COBYLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90600b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CUBIC BEZIER OPTIMIZATION\n",
      "Using 5 initial paths from Monte Carlo results\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Running COBYLA Optimization\n",
      "======================================================================\n",
      "\n",
      "[COBYLA 1/5] hemi=right\n",
      "  Objective: -0.755261  ObstDist: 7.462  PathLen: 88.479\n",
      "  Elapsed: 287.691s  Iterations: 20\n",
      "\n",
      "[COBYLA 2/5] hemi=right\n",
      "  Objective: -0.702756  ObstDist: 6.983  PathLen: 86.924\n",
      "  Elapsed: 290.364s  Iterations: 20\n",
      "\n",
      "[COBYLA 3/5] hemi=right\n",
      "  Objective: -0.754535  ObstDist: 7.370  PathLen: 71.447\n",
      "  Elapsed: 355.417s  Iterations: 20\n",
      "\n",
      "[COBYLA 4/5] hemi=right\n",
      "  Objective: -0.438899  ObstDist: 4.608  PathLen: 86.750\n",
      "  Elapsed: 475.615s  Iterations: 20\n",
      "\n",
      "[COBYLA 5/5] hemi=left\n",
      "  Objective: -0.486335  ObstDist: 5.087  PathLen: 90.284\n",
      "  Elapsed: 261.873s  Iterations: 20\n",
      "\n",
      "[COBYLA Summary] Total time: 1670.960s  Total iterations: 100\n",
      "\n",
      "======================================================================\n",
      "Best Result\n",
      "======================================================================\n",
      "  Hemisphere: right\n",
      "  Objective: -0.755261\n",
      "  Obstacle Distance: 7.462\n",
      "  Path Length: 88.479\n"
     ]
    }
   ],
   "source": [
    "# Run mono-criteria optimization\n",
    "print(\"STARTING CUBIC BEZIER OPTIMIZATION\")\n",
    "print(f\"Using {len(initial_paths)} initial paths from Monte Carlo results\\n\")\n",
    "\n",
    "# Run optimization across all initial paths\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Running {OPTIMIZATION_METHOD} Optimization\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "match OPTIMIZATION_METHOD:\n",
    "    case 'Nelder-Mead':\n",
    "        options = {\n",
    "            'maxiter': opt_max_iterations,\n",
    "            'xatol': opt_tolerance,\n",
    "            'fatol': opt_tolerance,\n",
    "            'disp': False\n",
    "        }\n",
    "    case 'COBYLA':\n",
    "        options = {\n",
    "            'maxiter': opt_max_iterations,\n",
    "            'tol': opt_tolerance,\n",
    "            'disp': False\n",
    "        }\n",
    "    case 'Powell':\n",
    "        options = {\n",
    "            'maxiter': opt_max_iterations,\n",
    "            'xtol': opt_tolerance,\n",
    "            'ftol': opt_tolerance,\n",
    "            'disp': False\n",
    "        }\n",
    "    case _:\n",
    "        raise ValueError(f\"Unknown optimization method: {OPTIMIZATION_METHOD}\")\n",
    "\n",
    "best_rec, all_records = run_multistart_bezier(OPTIMIZATION_METHOD, options)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Best Result\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Hemisphere: {best_rec['hemi']}\")\n",
    "print(f\"  Objective: {best_rec['objective']:.6f}\")\n",
    "print(f\"  Obstacle Distance: {best_rec['obstacle_distance']:.3f}\")\n",
    "print(f\"  Path Length: {best_rec['path_length']:.3f}\")\n",
    "\n",
    "# Store optimal results for later use\n",
    "opt_optimal_start = best_rec['start']\n",
    "opt_optimal_end = best_rec['end']\n",
    "P1_opt = best_rec['P1']\n",
    "P2_opt = best_rec['P2']\n",
    "opt_optimal_objective = best_rec['objective']\n",
    "opt_obstacle_dist = best_rec['obstacle_distance']\n",
    "opt_path_length = best_rec['path_length']\n",
    "opt_optimal_line = best_rec['line']\n",
    "optimal_curve_points = best_rec['path_points']\n",
    "selected_hemisphere = best_rec['hemi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e080c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved COBYLA optimized bezier path to cobyla_optimal_bezier_path.csv\n"
     ]
    }
   ],
   "source": [
    "## Save optimized bezier path to file\n",
    "opt_output_file = f\"{OPTIMIZATION_METHOD.lower()}_optimal_bezier_path.csv\"\n",
    "\n",
    "# Recompute normalized weighted objective for saved record\n",
    "if max_obstacle_dist and max_obstacle_dist > 0:\n",
    "    opt_norm_obstacle = opt_obstacle_dist / max_obstacle_dist\n",
    "else:\n",
    "    opt_norm_obstacle = opt_obstacle_dist / 100.0\n",
    "if max_path_length and max_path_length > 0:\n",
    "    opt_norm_length = opt_path_length / max_path_length\n",
    "else:\n",
    "    opt_norm_length = opt_path_length / 200.0\n",
    "opt_weighted_obj = -w_obstacle_norm * opt_norm_obstacle + w_path_length_norm * opt_norm_length\n",
    "\n",
    "with open(opt_output_file, 'w') as f:\n",
    "    f.write(\"hemisphere,start_x,start_y,start_z,end_x,end_y,end_z,p1_x,p1_y,p1_z,p2_x,p2_y,p2_z,obstacle_distance,path_length,weighted_objective\\n\")\n",
    "    f.write(\n",
    "        f\"{best_rec['hemi']},{best_rec['start'][0]},{best_rec['start'][1]},{best_rec['start'][2]},\"\n",
    "        f\"{best_rec['end'][0]},{best_rec['end'][1]},{best_rec['end'][2]},\"\n",
    "        f\"{best_rec['P1'][0]},{best_rec['P1'][1]},{best_rec['P1'][2]},\"\n",
    "        f\"{best_rec['P2'][0]},{best_rec['P2'][1]},{best_rec['P2'][2]},\"\n",
    "        f\"{best_rec['obstacle_distance']},{best_rec['path_length']},{opt_weighted_obj}\\n\"\n",
    "    )\n",
    "print(f\"Saved {OPTIMIZATION_METHOD} optimized bezier path to {opt_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d206d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Curve info - radius of curvature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83102dc",
   "metadata": {},
   "source": [
    "### Compare with Monte Carlo Results\n",
    "\n",
    "Compare the weighted-sum optimized curved path with the best Monte Carlo path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93959517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Comparison: Monte Carlo vs COBYLA Optimization\n",
      "============================================================\n",
      "\n",
      "Monte Carlo (best of 20 successful):\n",
      "  Obstacle distance: 5.720\n",
      "  Path length: 91.832\n",
      "  Weighted sum: -0.556074\n",
      "\n",
      "Weighted Sum (COBYLA) Optimization:\n",
      "  Obstacle distance: 7.462\n",
      "  Path length: 88.479\n",
      "  Weighted sum: -0.755255\n"
     ]
    }
   ],
   "source": [
    "if successful_attempts and opt_optimal_line is not None:\n",
    "    mc_best_hemi, mc_best_start, mc_best_end, mc_best_P1, mc_best_P2, mc_best_obstacle_dist, mc_best_path_len = successful_attempts[0]\n",
    "    mc_best_path_length = mc_best_path_len\n",
    "    \n",
    "    # Compute weighted sum for Monte Carlo best\n",
    "    norm_mc_obstacle = mc_best_obstacle_dist / max_obstacle_dist if max_obstacle_dist > 0 else 0\n",
    "    norm_mc_length = mc_best_path_length / max_path_length if max_path_length > 0 else 0\n",
    "    mc_weighted_sum = -w_obstacle_norm * norm_mc_obstacle + w_path_length_norm * norm_mc_length\n",
    "    \n",
    "    # Compute weighted sum for optimized path\n",
    "    norm_opt_obstacle = opt_obstacle_dist / max_obstacle_dist if max_obstacle_dist > 0 else 0\n",
    "    norm_opt_length = opt_path_length / max_path_length if max_path_length > 0 else 0\n",
    "    opt_weighted_sum = -w_obstacle_norm * norm_opt_obstacle + w_path_length_norm * norm_opt_length\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Comparison: Monte Carlo vs {OPTIMIZATION_METHOD} Optimization\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nMonte Carlo (best of {len(successful_attempts)} successful):\")\n",
    "    print(f\"  Obstacle distance: {mc_best_obstacle_dist:.3f}\")\n",
    "    print(f\"  Path length: {mc_best_path_length:.3f}\")\n",
    "    print(f\"  Weighted sum: {mc_weighted_sum:.6f}\")\n",
    "    \n",
    "    print(f\"\\nWeighted Sum ({OPTIMIZATION_METHOD}) Optimization:\")\n",
    "    print(f\"  Obstacle distance: {opt_obstacle_dist:.3f}\")\n",
    "    print(f\"  Path length: {opt_path_length:.3f}\")\n",
    "    print(f\"  Weighted sum: {opt_weighted_sum:.6f}\")\n",
    "else:\n",
    "    print(\"No Monte Carlo results available for comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8ed39",
   "metadata": {},
   "source": [
    "## Load Path Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98a52888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best Monte Carlo path: hemi=right obstacle_dist=5.720 path_len=91.832\n",
      "Loaded 21 Monte Carlo path records from monte_carlo_bezier_paths.csv\n"
     ]
    }
   ],
   "source": [
    "## Load Monte Carlo bezier path coordinates from file\n",
    "input_file = \"monte_carlo_bezier_paths.csv\"\n",
    "monte_carlo_records = []\n",
    "\n",
    "import csv\n",
    "if os.path.exists(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                record = {\n",
    "                    'hemisphere': row['hemisphere'],\n",
    "                    'start': (\n",
    "                        float(row['start_x']),\n",
    "                        float(row['start_y']),\n",
    "                        float(row['start_z'])\n",
    "                    ),\n",
    "                    'end': (\n",
    "                        float(row['end_x']),\n",
    "                        float(row['end_y']),\n",
    "                        float(row['end_z'])\n",
    "                    ),\n",
    "                    'P1': (\n",
    "                        float(row['p1_x']),\n",
    "                        float(row['p1_y']),\n",
    "                        float(row['p1_z'])\n",
    "                    ),\n",
    "                    'P2': (\n",
    "                        float(row['p2_x']),\n",
    "                        float(row['p2_y']),\n",
    "                        float(row['p2_z'])\n",
    "                    ),\n",
    "                    'obstacle_distance': float(row['obstacle_distance']),\n",
    "                    'path_length': float(row['path_length']),\n",
    "                    'status': row['status'],\n",
    "                    'is_best': (row.get('is_best', '0') == '1')\n",
    "                }\n",
    "                monte_carlo_records.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipping row due to parse error: {e}\")\n",
    "\n",
    "    # Rebuild successful_attempts\n",
    "    successful_attempts = []\n",
    "    \n",
    "    for r in monte_carlo_records:\n",
    "        if r['status'] == 'success':\n",
    "            successful_attempts.append((r['hemisphere'], r['start'], r['end'], r['P1'], r['P2'], r['obstacle_distance'], r['path_length']))\n",
    "\n",
    "    # Rebuild failed_attempts\n",
    "    failed_attempts = []\n",
    "    for r in monte_carlo_records:\n",
    "        if r['status'] == 'fail':\n",
    "            failed_attempts.append((r['hemisphere'], r['start'], r['end'], r['P1'], r['P2'], r['obstacle_distance'], r['path_length']))\n",
    "    \n",
    "    # Identify best path\n",
    "    loaded_best = next((r for r in monte_carlo_records if r['status'] == 'success' and r['is_best']), None)\n",
    "    if loaded_best:\n",
    "        print(f\"Loaded best Monte Carlo path: hemi={loaded_best['hemisphere']} obstacle_dist={loaded_best['obstacle_distance']:.3f} path_len={loaded_best['path_length']:.3f}\")\n",
    "    else:\n",
    "        print(\"Best Monte Carlo path flag not found; will infer later if needed.\")\n",
    "    print(f\"Loaded {len(monte_carlo_records)} Monte Carlo path records from {input_file}\")\n",
    "else:\n",
    "    print(f\"[INFO] Monte Carlo path file not found: {input_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef735f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load optimized bezier path from file\n",
    "OPTIMIZATION_METHOD = 'COBYLA'  # Ensure this matches the saved optimization method\n",
    "\n",
    "opt_input_file = f\"{OPTIMIZATION_METHOD.lower()}_optimal_bezier_path.csv\"\n",
    "# Read optimal path from CSV and rebuild variables\n",
    "if os.path.exists(opt_input_file):\n",
    "    with open(opt_input_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        row = next(reader, None)\n",
    "        if row:\n",
    "            opt_hemisphere = row['hemisphere']\n",
    "            opt_optimal_start = (float(row['start_x']), float(row['start_y']), float(row['start_z']))\n",
    "            opt_optimal_end = (float(row['end_x']), float(row['end_y']), float(row['end_z']))\n",
    "            P1_opt = (float(row['p1_x']), float(row['p1_y']), float(row['p1_z']))\n",
    "            P2_opt = (float(row['p2_x']), float(row['p2_y']), float(row['p2_z']))\n",
    "            opt_obstacle_dist = float(row['obstacle_distance'])\n",
    "            opt_path_length = float(row['path_length'])\n",
    "            opt_weighted_obj = float(row.get('weighted_objective', -w_obstacle_norm * (opt_obstacle_dist / max_obstacle_dist if max_obstacle_dist else opt_obstacle_dist / 100.0)\n",
    "                                            + w_path_length_norm * (opt_path_length / max_path_length if max_path_length else opt_path_length / 200.0)))\n",
    "            selected_hemisphere = opt_hemisphere\n",
    "            path_points = sample_bezier_points(opt_optimal_start, P1_opt, P2_opt, opt_optimal_end, num_samples=200)\n",
    "            opt_optimal_line = Line(path_points).c(\"cyan\").lw(10)\n",
    "            print(f\"Loaded {OPTIMIZATION_METHOD} path: hemi={opt_hemisphere} obstacle={opt_obstacle_dist:.3f} length={opt_path_length:.3f} weighted={opt_weighted_obj:.6f}\")\n",
    "        else:\n",
    "            print(f\"[INFO] {OPTIMIZATION_METHOD} file is empty.\")\n",
    "else:\n",
    "    print(f\"[INFO] {OPTIMIZATION_METHOD} path file not found: {opt_input_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68254908",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "030a3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set vedo backend to pop out plots in separate windows\n",
    "vedo.settings.default_backend = 'vtk' # or 'vt' or '2d' or 'k3d' or 'ipyvtklink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5eae680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering scene with optimized path (cyan)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vedo.plotter.Plotter at 0x1da77ea5280>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Plot final results\n",
    "NUM_FAILED_TO_SHOW = min(10, len(failed_lines))\n",
    "NUM_SUBOPTIMAL_TO_SHOW = min(10, len(suboptimal_lines))\n",
    "\n",
    "actors = []\n",
    "if merged_full_brain: actors.append(merged_full_brain)\n",
    "if merged_skin: actors.append(merged_skin)\n",
    "\n",
    "if selected_hemisphere == 'left':\n",
    "    if merged_left_entry_zone:\n",
    "        actors.append(merged_left_entry_zone.clone().alpha(0.08))\n",
    "    if merged_right_entry_zone:\n",
    "        actors.append(merged_right_entry_zone.clone().alpha(0.02))\n",
    "    if merged_left_stn:\n",
    "        actors.append(merged_left_stn.clone().alpha(0.9))\n",
    "    if merged_right_stn:\n",
    "        actors.append(merged_right_stn.clone().alpha(0.3))\n",
    "elif selected_hemisphere == 'right':\n",
    "    if merged_left_entry_zone:\n",
    "        actors.append(merged_left_entry_zone.clone().alpha(0.02))\n",
    "    if merged_right_entry_zone:\n",
    "        actors.append(merged_right_entry_zone.clone().alpha(0.08))\n",
    "    if merged_left_stn:\n",
    "        actors.append(merged_left_stn.clone().alpha(0.3))\n",
    "    if merged_right_stn:\n",
    "        actors.append(merged_right_stn.clone().alpha(0.9))\n",
    "else:\n",
    "    if merged_left_entry_zone: actors.append(merged_left_entry_zone)\n",
    "    if merged_right_entry_zone: actors.append(merged_right_entry_zone)\n",
    "    if merged_left_stn: actors.append(merged_left_stn)\n",
    "    if merged_right_stn: actors.append(merged_right_stn)\n",
    "\n",
    "if merged_obstacles: actors.append(merged_obstacles.clone().alpha(0.7))\n",
    "\n",
    "actors.extend(failed_lines[:NUM_FAILED_TO_SHOW])\n",
    "actors.extend(suboptimal_lines[:NUM_SUBOPTIMAL_TO_SHOW])\n",
    "if best_path:\n",
    "    mc_best_faded = best_path.clone().alpha(0.6)\n",
    "    actors.append(mc_best_faded)\n",
    "\n",
    "try:\n",
    "    actors.append(opt_optimal_line)\n",
    "except:\n",
    "    print(\"Optimized path not found.\")\n",
    "\n",
    "print(f\"Rendering scene with optimized path (cyan)...\")\n",
    "show(actors, axes=1, viewup=\"z\", \n",
    "     title=f\"Optimized Path\", new=True, interactive=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
